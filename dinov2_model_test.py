import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader, random_split
from transformers import AutoImageProcessor, AutoModel
from PIL import Image, ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True
import os
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from typing import Dict, List, Tuple, Optional, Any
import numpy as np
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, average_precision_score
)
from sklearn.preprocessing import label_binarize
from torch.utils.data import default_collate
import logging
import time
from torch.utils.tensorboard import SummaryWriter
import torchvision.transforms as T

# --- é…ç½®å‚æ•° ---
MODEL_NAME = "facebook/dinov2-base" 
TARGET_IMAGE_SIZE = 518 # å›¾åƒç›®æ ‡å°ºå¯¸
BATCH_SIZE = 64
LEARNING_RATE = 5e-4
NUM_EPOCHS = 100
PATIENCE = 50 # æ—©åœè€å¿ƒå€¼
Abstraction_dim = 1024
WEIGHT_DECAY = 1e-4

# è‡ªåŠ¨é€‰æ‹© GPU è®¾å¤‡ï¼Œä¼˜å…ˆä½¿ç”¨ cuda:0
DEVICE = "cuda:0"
if torch.cuda.is_available():
    # ä½¿ç”¨ç”¨æˆ·å®šä¹‰çš„é€»è¾‘ï¼Œä½†ä¿®æ­£ä¸ºå¯ç”¨è®¾å¤‡
    device_id = 1 if torch.cuda.device_count() > 2 else 0
    DEVICE = f"cuda:{device_id}"
else:
    DEVICE = "cpu"


# ç”¨æˆ·æä¾›çš„æ–‡ä»¶è·¯å¾„
TRAIN_NAME = "BTXRD"
TRAIN_CSV_PATH = "/home/yyi/data/BTXRD_train.csv"
VAL_CSV_PATH = "/home/yyi/data/BTXRD_val.csv"
CSV_PATH = "/home/yyi/data/test_dataset/FracAtlas_dataset.csv" # æ ‡ç­¾CSVæ–‡ä»¶è·¯å¾„
IMAGE_PATH_COLUMN = 'image_id' # CSVä¸­åŒ…å«å›¾åƒç›¸å¯¹è·¯å¾„çš„åˆ—å
LABEL_COLUMNS = ['tumor','benign','malignant'] # æ‚¨çš„æ‰€æœ‰æ ‡ç­¾åˆ—å
LOAD_LOCAL_CHECKPOINT = True
TEST_NAME = "boneDinov2_518"
TEST_NAME = f"{TEST_NAME}_{TRAIN_NAME}"
LOCAL_CHECKPOINT_PATH = "/home/yyi/weight/rad_dino.pth" # æ›¿æ¢ä¸ºæ‚¨çš„æœ¬åœ° .pth æ–‡ä»¶è·¯å¾„
DATA_ROOT_CHECKPOINT = False
DATA_ROOT = "/data/truenas_B2/yyi/data/boneage-training-dataset" # å›¾åƒçš„æ ¹ç›®å½•

# **æ–°å¢ï¼šæ—¥å¿—é…ç½®å‡½æ•°**
FILENAME = f"{TEST_NAME}_{TARGET_IMAGE_SIZE}_{time.strftime('%Y%m%d-%H%M%S')}"
LOG_FILENAME = os.path.join(f'logs/', f"{FILENAME}.log")


def setup_logging():
    """é…ç½®æ—¥å¿—è®°å½•ï¼Œè¾“å‡ºåˆ°æ–‡ä»¶å’Œæ§åˆ¶å°ã€‚"""
    if logging.getLogger().hasHandlers():
        return logging.getLogger(__name__)

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(LOG_FILENAME), # å†™å…¥æ–‡ä»¶
            logging.StreamHandler() # è¾“å‡ºåˆ°æ§åˆ¶å°
        ]
    )
    return logging.getLogger(__name__)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              
logger = setup_logging() # åˆå§‹åŒ–å…¨å±€æ—¥å¿—è®°å½•å™¨


# --- è‡ªå®šä¹‰ PyTorch Dataset (å¤„ç†å¤šåˆ—åˆ†ç±»æ ‡ç­¾) ---
class MultiTaskImageDataset(Dataset):
    """
    å¤šä»»åŠ¡å›¾åƒæ•°æ®é›†ã€‚æ”¯æŒå¤šä¸ªæ ‡ç­¾åˆ—ï¼Œå¹¶å°†æ¯ä¸ªå¤šç±»åˆ«æ ‡ç­¾è½¬æ¢ä¸º OvR (One-vs-Rest) äºŒåˆ†ç±»ä»»åŠ¡ã€‚
    
    å‚æ•°:
        root_dir (str): å›¾åƒæ–‡ä»¶æ‰€åœ¨çš„æ ¹ç›®å½•ã€‚
        csv_path (str): åŒ…å«å›¾åƒè·¯å¾„å’Œæ ‡ç­¾çš„ CSV æ–‡ä»¶è·¯å¾„ã€‚
        img_col (str): å›¾åƒè·¯å¾„åœ¨ CSV ä¸­çš„åˆ—åã€‚
        label_cols (List[str]): åŸå§‹æ ‡ç­¾åˆ—ååˆ—è¡¨ã€‚
        processor (AutoImageProcessor): Hugging Face å›¾åƒé¢„å¤„ç†å™¨ã€‚
        size (int): å›¾åƒç›®æ ‡å°ºå¯¸ã€‚
        logger (logging.Logger): æ—¥å¿—è®°å½•å™¨ã€‚
        fitted_encoders (Dict[str, Any], optional): é¢„å…ˆæ‹Ÿåˆçš„ç¼–ç å™¨å’Œä»»åŠ¡ä¿¡æ¯ï¼Œç”¨äºéªŒè¯é›†ã€‚
                                                     é”®åº”åŒ…æ‹¬ 'label_encoders', 'ovr_tasks_map' ç­‰ã€‚
    """
    def __init__(self, root_dir: str, csv_path: str, img_col: str, label_cols: List[str], 
                 processor: AutoImageProcessor, size: int, logger: logging.Logger, 
                 fitted_encoders: Dict[str, Any] = None, is_training: bool = False):
        
        self.root_dir = root_dir
        self.processor = processor
        self.size = size
        self.logger = logger
        self.label_cols = label_cols
        self.is_training = is_training
        
        try:
            self.df = pd.read_csv(csv_path)
            # ç§»é™¤å›¾åƒè·¯å¾„ä¸ºç©ºæˆ–ç¼ºå¤±çš„è¡Œ
            self.df.dropna(subset=[img_col], inplace=True)
        except Exception as e:
            logger.critical(f"æ— æ³•è¯»å–æˆ–å¤„ç† CSV æ–‡ä»¶ {csv_path}: {e}")
            raise

        self.img_col = img_col
        self.label_encoders: Dict[str, LabelEncoder] = {}
        self.ovr_tasks_map: Dict[str, List[str]] = {} # åŸå§‹ä»»åŠ¡å -> å¯¹åº”çš„ OvR ä»»åŠ¡ååˆ—è¡¨
        self.num_classes_per_task: Dict[str, int] = {} # OvR ä»»åŠ¡å -> ç±»åˆ«æ•° (å§‹ç»ˆä¸º 2)
        self.all_task_names: List[str] = [] # æ‰€æœ‰ OvR ä»»åŠ¡å

        if fitted_encoders is None:
            # è®­ç»ƒæ¨¡å¼ï¼šæ‹Ÿåˆç¼–ç å™¨å¹¶åˆ›å»º OvR ä»»åŠ¡
            self._fit_encoders()
        else:
            # éªŒè¯æ¨¡å¼ï¼šä½¿ç”¨æ‹Ÿåˆå¥½çš„ç¼–ç å™¨å’Œä»»åŠ¡æ˜ å°„
            self.label_encoders = fitted_encoders['label_encoders']
            self.ovr_tasks_map = fitted_encoders['ovr_tasks_map']
            self.all_task_names = fitted_encoders['all_task_names']
            # æ‰€æœ‰ OvR ä»»åŠ¡éƒ½æ˜¯äºŒåˆ†ç±»
            self.num_classes_per_task = {task: 2 for task in self.all_task_names}
            
            self._transform_labels()

        logger.info(f"æ•°æ®é›† {csv_path} åŠ è½½æˆåŠŸï¼Œæ€»æ ·æœ¬æ•°: {len(self.df)}")
        logger.info(f"åˆ›å»ºçš„ OvR ä»»åŠ¡æ€»æ•°: {len(self.all_task_names)}")

        # æ•°æ®å¢å¼º
        if self.is_training:
            # è®­ç»ƒé›†ä½¿ç”¨éšæœºå¢å¼º
            self.transform = T.Compose([
                T.RandomHorizontalFlip(p=0.5),
                T.RandomRotation(degrees=15),
                T.RandomAffine(degrees=0,translate=(0.1, 0.1),shear=0),
            ])
            self.logger.info("âœ… è®­ç»ƒé›†å·²å¯ç”¨æ•°æ®å¢å¼ºã€‚")
        else:
            # éªŒè¯é›†ä¸ä½¿ç”¨éšæœºå¢å¼º
            self.transform = None
            self.logger.info("éªŒè¯é›†æœªå¯ç”¨æ•°æ®å¢å¼ºã€‚")


    def _fit_encoders(self):
        """åœ¨è®­ç»ƒé›†ä¸Šæ‹Ÿåˆ LabelEncoder å¹¶ç”Ÿæˆ OvR ä»»åŠ¡ã€‚"""
        for col in self.label_cols:
            le = LabelEncoder()
            # æ‹Ÿåˆå¹¶è½¬æ¢åŸå§‹æ ‡ç­¾
            try:
                self.df[col + '_encoded'] = le.fit_transform(self.df[col].astype(str))
            except Exception as e:
                self.logger.error(f"æ— æ³•å¯¹åˆ— {col} è¿›è¡Œ fit_transform: {e}")
                continue

            self.label_encoders[col] = le
            original_classes = le.classes_.tolist()
            ovr_tasks = []
            original_label_str = self.df[col].astype(str)
            num_unique_classes = len(original_classes)

            if num_unique_classes <= 2:
                ovr_task_name = col  # ä¿æŒåŸå§‹ä»»åŠ¡å
                self.all_task_names.append(ovr_task_name)
                self.num_classes_per_task[ovr_task_name] = 2 # ä»æ˜¯äºŒåˆ†ç±»
                self.ovr_tasks_map[col] = [col] # æ˜ å°„åˆ°è‡ªèº«
                self.df[ovr_task_name] = self.df[col + '_encoded'] 
                self.logger.info(f"ä»»åŠ¡ '{col}' ä¸ºäºŒåˆ†ç±» (ç±»åˆ«æ•°: {num_unique_classes})ï¼Œè·³è¿‡ OvR è½¬æ¢ã€‚")
            else:
                for class_name in original_classes:
                    ovr_task_name = f"{col}_vs_{class_name}"
                    ovr_tasks.append(ovr_task_name)
                    
                    # åˆ›å»ºæ–°çš„ OvR æ ‡ç­¾åˆ— (0 æˆ– 1)
                    # 1: æ ·æœ¬å±äºè¯¥ç±»åˆ«ï¼Œ 0: æ ·æœ¬ä¸å±äºè¯¥ç±»åˆ«
                    self.df[ovr_task_name] = (original_label_str == class_name).astype(int)
                    
                    self.num_classes_per_task[ovr_task_name] = 2 # å§‹ç»ˆä¸º 2 (äºŒåˆ†ç±»)
                    self.all_task_names.append(ovr_task_name)
                
                self.ovr_tasks_map[col] = ovr_tasks
                self.logger.info(f"ä»»åŠ¡ '{col}' ä¸ºå¤šåˆ†ç±» (ç±»åˆ«æ•°: {num_unique_classes})ï¼Œå·²åˆ›å»º {len(ovr_tasks)} ä¸ª OvR ä»»åŠ¡ã€‚")

            
        
        self.logger.info("ç¼–ç å™¨å·²æ‹Ÿåˆï¼ŒOvR ä»»åŠ¡å·²åˆ›å»ºã€‚")


    def _transform_labels(self):
        """åœ¨éªŒè¯é›†ä¸Šä½¿ç”¨å·²æ‹Ÿåˆçš„ LabelEncoder è½¬æ¢æ ‡ç­¾ã€‚"""
        for col in self.label_cols:
            if col not in self.label_encoders:
                self.logger.error(f"åŸå§‹ä»»åŠ¡ {col} åœ¨æ‹Ÿåˆç¼–ç å™¨ä¸­ç¼ºå¤±ã€‚è·³è¿‡ã€‚")
                continue
            
            le = self.label_encoders[col]
            ovr_tasks = self.ovr_tasks_map.get(col, [])
            original_classes = le.classes_.tolist()
            num_unique_classes = len(original_classes)
            
            # ä½¿ç”¨ transform è½¬æ¢åŸå§‹æ ‡ç­¾
            # å¿…é¡»å¤„ç†åœ¨è®­ç»ƒé›†ä¸­æœªå‡ºç°çš„ç±»åˆ«ï¼ˆç”¨ nan æˆ–å…¶ä»–æ–¹å¼æ ‡è®°ï¼Œé€šå¸¸ LabelEncoder ä¼šæŠ¥é”™ï¼‰
            def transform_or_ignore(x):
                try:
                    return le.transform([x])[0]
                except ValueError:
                    # å¦‚æœéªŒè¯é›†æœ‰è®­ç»ƒé›†æœªè§çš„ç±»åˆ«ï¼Œè¿™é‡Œå°†å…¶è§†ä¸ºä¸€ä¸ªç‰¹æ®Šçš„ç±»åˆ«ï¼Œä½†åœ¨ OvR ä¸­å®ƒä»¬éƒ½å°†æ˜¯ 0
                    return -1 
            
            self.df[col + '_encoded'] = self.df[col].astype(str).apply(transform_or_ignore)

            # æ ¹æ® OvR ä»»åŠ¡æ˜ å°„åˆ›å»º OvR æ ‡ç­¾
            if num_unique_classes <= 2 and col in ovr_tasks:
                # è®­ç»ƒé›†å°†å…¶è§†ä¸ºäºŒåˆ†ç±»ï¼Œåˆ™éªŒè¯é›†ç›´æ¥ä½¿ç”¨ç¼–ç åçš„æ ‡ç­¾
                self.df[col] = self.df[col + '_encoded']
            elif num_unique_classes > 2:
                # å¤šåˆ†ç±»ï¼Œæ ¹æ® OvR ä»»åŠ¡æ˜ å°„åˆ›å»º OvR æ ‡ç­¾
                original_label_str = self.df[col].astype(str)
                for class_name in original_classes:
                    ovr_task_name = f"{col}_vs_{class_name}"
                    if ovr_task_name in ovr_tasks:
                        # 1: æ ·æœ¬å±äºè¯¥ç±»åˆ«ï¼Œ 0: æ ·æœ¬ä¸å±äºè¯¥ç±»åˆ«
                        self.df[ovr_task_name] = (original_label_str == class_name).astype(int)
        
        self.logger.info("æ ‡ç­¾å·²è½¬æ¢ã€‚")


    def __len__(self) -> int:
        return len(self.df)

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, Dict[str, torch.Tensor], str]:
        """
        è¿”å›: å›¾åƒ Tensor, æ ‡ç­¾å­—å…¸ (OvRä»»åŠ¡å -> æ ‡ç­¾Tensor), å›¾åƒæ–‡ä»¶è·¯å¾„
        æ³¨æ„: ä¸ºæ–¹ä¾¿è°ƒè¯•ï¼Œè¿”å›è·¯å¾„ï¼Œä½† collate_fn ä¼šè¿‡æ»¤æ‰
        """
        row = self.df.iloc[idx]
        img_path = os.path.join(self.root_dir, row[self.img_col])
        
        # 1. å°è¯•åŠ è½½å›¾åƒ
        try:
            image = Image.open(img_path).convert("RGB")
        except Exception as e:
            self.logger.warning(f"æ— æ³•åŠ è½½æˆ–æŸåçš„å›¾åƒæ–‡ä»¶ {img_path}: {e}")
            # è¿”å› None ä¿¡å·ï¼Œç”± custom_collate_fn è¿‡æ»¤
            return None, None, img_path 

        if self.transform is not None:
            image = self.transform(image)
        inputs = self.processor(images=image, size=self.size, return_tensors="pt")
        pixel_values = inputs["pixel_values"].squeeze(0) # [C, H, W]
        
        # 3. æå– OvR æ ‡ç­¾
        labels_dict = {}
        for task_name in self.all_task_names:
            # OvR æ ‡ç­¾æ˜¯ 0 æˆ– 1ï¼Œéœ€è¦æ˜¯ LongTensor
            label_value = row[task_name]
            labels_dict[task_name] = torch.tensor(label_value, dtype=torch.long)


        return pixel_values, labels_dict, img_path


# ====================================================================
# 2. custom_collate_fn å®ç°
# ====================================================================

def custom_collate_fn(batch: List[Any]) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:
    """
    è‡ªå®šä¹‰ collate_fnï¼Œç”¨äºå¤„ç† __getitem__ è¿”å› None çš„æƒ…å†µ (å¦‚å›¾åƒæŸå)ã€‚
    è¿‡æ»¤æ‰æŸåçš„æ ·æœ¬ï¼Œç„¶åå°†æœ‰æ•ˆçš„æ ·æœ¬æ‰“åŒ…æˆ Tensorã€‚
    """
    # è¿‡æ»¤æ‰ None æ ·æœ¬ (ç”±æŸåå›¾åƒå¼•èµ·)
    batch = [item for item in batch if item[0] is not None]
    
    if not batch:
        # å¦‚æœæ‰¹æ¬¡ä¸­æ‰€æœ‰æ ·æœ¬éƒ½æŸåï¼Œè¿”å› None
        return None 

    # 1. å›¾åƒå †å 
    pixel_values = torch.stack([item[0] for item in batch])
    
    # 2. æ ‡ç­¾å­—å…¸å¤„ç†
    # æå–ç¬¬ä¸€ä¸ªæ ·æœ¬çš„æ ‡ç­¾å­—å…¸ä¸­çš„æ‰€æœ‰ä»»åŠ¡å
    task_names = list(batch[0][1].keys())
    
    labels_dict = {}
    for task_name in task_names:
        # æ”¶é›†è¯¥ä»»åŠ¡çš„æ‰€æœ‰æ ‡ç­¾å¹¶å †å 
        labels = [item[1][task_name] for item in batch]
        labels_dict[task_name] = torch.stack(labels).squeeze(0) # å †å åå½¢çŠ¶åº”ä¸º [N]

    # è¿”å›å›¾åƒå’Œæ ‡ç­¾å­—å…¸
    img_paths = [item[2] for item in batch]
    return pixel_values, labels_dict, img_paths

# --- è‡ªå®šä¹‰æ¨¡å‹ï¼šDINOv3 + å¤šä¸ªåˆ†ç±»å¤´ ---

class DinoV3MultiTaskClassifier(nn.Module):
    """
    åŸºäº DINOv3 ä¸»å¹²ç½‘ç»œï¼Œå¸¦æœ‰å¤šä»»åŠ¡åˆ†ç±»å¤´ã€‚
    """
    def __init__(self, model_name: str, task_num_classes: Dict[str, int]):
        super().__init__()

        self.task_names = list(task_num_classes.keys())

        # 1. åŠ è½½ DINOv3 ä¸»å¹²ç½‘ç»œå¹¶å†»ç»“
        self.backbone = AutoModel.from_pretrained(model_name)
        self.input_device = torch.device(DEVICE)
        feature_dim = self.backbone.config.hidden_size

        # ==================== æ ¹æ®å…¨å±€å˜é‡åŠ è½½æœ¬åœ°æ£€æŸ¥ç‚¹ ====================
        global LOAD_LOCAL_CHECKPOINT, LOCAL_CHECKPOINT_PATH

        if LOAD_LOCAL_CHECKPOINT:
            if os.path.exists(LOCAL_CHECKPOINT_PATH):
                logger.info(f"Global flag LOAD_LOCAL_CHECKPOINT is True. Loading full model checkpoint from: {LOCAL_CHECKPOINT_PATH}")
                try:
                    checkpoint = torch.load(LOCAL_CHECKPOINT_PATH, map_location='cpu')

                    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                        state_dict = checkpoint['model_state_dict']
                    elif isinstance(checkpoint, dict) and 'teacher' in checkpoint:
                        logger.info("Assuming DINOv2 official checkpoint format ('teacher' key).")
                        state_dict = checkpoint['teacher']
                    else:
                        state_dict = checkpoint

                    backbone_state_dict = {}
                    for k, v in state_dict.items():
                        if k.startswith('backbone.'):
                            new_key = k[len('backbone.'):]  # å»æ‰ 'backbone.' å‰ç¼€
                            backbone_state_dict[new_key] = v
                    # è§£å†³ mask_token å°ºå¯¸ä¸åŒ¹é…é—®é¢˜ (DINOv2/v3 ç‰¹æœ‰)
                    if 'embeddings.mask_token' in backbone_state_dict:
                        mask_token = backbone_state_dict['embeddings.mask_token']
                        if mask_token.dim() == 2:  # [1, dim] -> éœ€è¦ [1, 1, dim]
                            logger.info("Reshaping mask_token from [1, dim] to [1, 1, dim]")
                            backbone_state_dict['embeddings.mask_token'] = mask_token.unsqueeze(1)
                        
                    missing, unexpected = self.backbone.load_state_dict(backbone_state_dict, strict=False)
                    logger.info("âœ… Backbone checkpoint loaded successfully.")

                except Exception as e:
                    logger.error(f"Error loading checkpoint at {LOCAL_CHECKPOINT_PATH}: {e}")
                    logger.warning("Continuing with the model initialized from Hugging Face and random classifiers.")
            else:
                logger.error(f"Warning: Global flag LOAD_LOCAL_CHECKPOINT is True, but file not found at: {LOCAL_CHECKPOINT_PATH}")
        else:
            logger.error("Global flag LOAD_LOCAL_CHECKPOINT is False. Initializing model from scratch (Hugging Face backbone + new classifiers).")

        '''
        abstraction_dropout = 0.5
        if Abstraction_dim >= feature_dim:
            # å¦‚æœé™ç»´ç»´åº¦å¤§äºæˆ–ç­‰äºåŸå§‹ç»´åº¦ï¼Œåˆ™ä¸é™ç»´ï¼Œåªä¿ç•™ä¸€ä¸ªDropoutå±‚
            logger.warning(f"Abstraction dimension ({Abstraction_dim}) >= Feature dimension ({feature_dim}). Skipping feature abstraction/compression.")
            self.abstraction_layer = nn.Dropout(abstraction_dropout)
            final_feature_dim = feature_dim
        else:
            # å¼•å…¥éçº¿æ€§é™ç»´å’Œå¼ºæ­£åˆ™åŒ–
            self.abstraction_layer = nn.Sequential(
                nn.Linear(feature_dim, Abstraction_dim),
                nn.GELU(),
                nn.Dropout(abstraction_dropout)
            )
            final_feature_dim = Abstraction_dim
            logger.info(f"Classifier Head uses abstraction: {feature_dim} -> {final_feature_dim} with Dropout {abstraction_dropout}")


        
        '''
        
        # å†»ç»“ä¸»å¹²ç½‘ç»œ
        for param in self.backbone.parameters():
            param.requires_grad = False
        # å®šä¹‰å¤šä¸ªåˆ†ç±»å¤´
        self.classifiers = nn.ModuleDict()
        for task_name, num_classes in task_num_classes.items():
            # self.classifiers[task_name] = nn.Sequential(nn.Dropout(0.5),nn.Linear(feature_dim, num_classes))
            self.classifiers[task_name] = nn.Linear(feature_dim, num_classes)
            for param in self.classifiers[task_name].parameters():
                 param.requires_grad = True
        
        # for param in self.abstraction_layer.parameters():
        #    param.requires_grad = True

        
    def forward(self, pixel_values: torch.Tensor) -> Dict[str, torch.Tensor]:
        # è¿è¡Œä¸»å¹²ç½‘ç»œï¼ˆå†»ç»“ï¼‰
        pixel_values = pixel_values.to(self.input_device)
        
        # å³ä½¿ä¸»å¹²ç½‘ç»œå†»ç»“ï¼Œä¹Ÿè¦ç¡®ä¿å®ƒåœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Šè¿è¡Œ
        with torch.no_grad():
            outputs = self.backbone(pixel_values=pixel_values)

        # pooler_output æå–å…¨å±€ç‰¹å¾ (CLS Token)
        global_feature = outputs.last_hidden_state[:, 0, :]

        # æ­£åˆ™
        # abstracted_feature = self.abstraction_layer(global_feature)

        # è¿è¡Œå„ä¸ªåˆ†ç±»å¤´
        logits = {}
        for task_name in self.task_names:
            logits[task_name] = self.classifiers[task_name](global_feature)

        return logits


# --- è¯„ä¼°å‡½æ•° ---
def calculate_metrics_binarized(
        all_labels: List[int],
        all_preds: List[int],
        all_probs: List[List[float]],
        unique_labels: List[int],
        pos_label: Optional[int] = None,
        mode: str = 'test',
        logger: logging.Logger = logging.getLogger(__name__)
) -> Dict[str, float]:
    """è®¡ç®—äºŒåˆ†ç±»æˆ–å¤šåˆ†ç±»æ¨¡å‹çš„è¯„ä¼°æŒ‡æ ‡ã€‚"""
    all_labels_np = np.array(all_labels)
    all_preds_np = np.array(all_preds)
    all_probs_np = np.array(all_probs)
    n_classes = len(unique_labels)

    if len(all_labels_np) == 0:
        logger.warning(f"è­¦å‘Š: {mode.upper()} æ•°æ®é›†ä¸ºç©ºï¼Œè·³è¿‡æŒ‡æ ‡è®¡ç®—ã€‚")
        return {'accuracy': 0.0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auroc': float('nan'), 'auprc': float('nan')}

    metrics = {}
    metrics['accuracy'] = accuracy_score(all_labels_np, all_preds_np)
    metrics['precision'] = precision_score(all_labels_np, all_preds_np, average='weighted', zero_division=0)
    metrics['recall'] = recall_score(all_labels_np, all_preds_np, average='weighted', zero_division=0)
    metrics['f1'] = f1_score(all_labels_np, all_preds_np, average='weighted', zero_division=0)

    logger.info(f"--- {mode.upper()} ç»“æœ (ç±»åˆ«æ•°: {n_classes}) ---")
    logger.info(f"æ•´ä½“å‡†ç¡®ç‡ (Accuracy): {metrics['accuracy'] * 100:.2f}%")
    logger.info(f"æ•´ä½“ç²¾ç¡®ç‡ (Precision): {metrics['precision'] * 100:.2f}%")
    logger.info(f"æ•´ä½“å¬å›ç‡ (Recall): {metrics['recall'] * 100:.2f}%")
    logger.info(f"æ•´ä½“ F1-Score: {metrics['f1'] * 100:.2f}%")

    # --- AUROC ---
    try:
        if n_classes == 2:
            # äºŒåˆ†ç±»ï¼šéœ€è¦çŸ¥é“å“ªä¸ªæ˜¯æ­£ç±» (pos_label=1 é»˜è®¤)
            pos_index = unique_labels.index(pos_label) if pos_label in unique_labels else 1
            y_score = all_probs_np[:, pos_index]
            metrics['auroc'] = roc_auc_score(all_labels_np, y_score)
        else:
            # å¤šåˆ†ç±»ï¼šä½¿ç”¨ OVR (One vs Rest) å’ŒåŠ æƒå¹³å‡
            labels_bin = label_binarize(all_labels_np, classes=unique_labels)
            metrics['auroc'] = roc_auc_score(
                labels_bin, all_probs_np, average='weighted', multi_class='ovr'
            )
        logger.info(f"AUROC (weighted/binary): {metrics['auroc']:.4f}")
    except Exception as e:
        logger.warning(f"âš ï¸ AUROC è®¡ç®—å¤±è´¥: {e}")
        metrics['auroc'] = float('nan')

    # --- AUPRC ---
    try:
        # AUPRC åœ¨å¤šåˆ†ç±»ä¸­ä¹Ÿä½¿ç”¨æ ‡ç­¾äºŒå€¼åŒ–
        labels_bin = label_binarize(all_labels_np, classes=unique_labels)
        if n_classes == 2:
            # äºŒåˆ†ç±» AUPRC
            pos_label_int = 1
            pos_index = unique_labels.index(pos_label) if pos_label in unique_labels else 1
            y_score = all_probs_np[:, pos_index]
            metrics['auprc'] = average_precision_score(
                all_labels_np, 
                y_score, 
                pos_label=pos_label_int
            )
        else:
            # å¤šåˆ†ç±» AUPRC
            metrics['auprc'] = average_precision_score(
                labels_bin, all_probs_np, average='weighted'
            )
        logger.info(f"AUPRC (weighted/binary): {metrics['auprc']:.4f}")
    except Exception as e:
        logger.warning(f"âš ï¸ AUPRC è®¡ç®—å¤±è´¥: {e}")
        metrics['auprc'] = float('nan')

    return metrics

        
# --- è¾…åŠ©å‡½æ•°ï¼šè¯„ä¼°æµç¨‹ ---
def evaluate(model, data_loader, criterion, task_names, num_classes_dict, device, mode, logger):
    # ... åˆå§‹åŒ– (ä¸åŸä»£ç ä¸€è‡´) ...
    model.eval()
    total_combined_loss = 0

    task_preds = {task: [] for task in task_names}
    task_labels = {task: [] for task in task_names}
    task_probs = {task: [] for task in task_names} # <--- æ–°å¢
    task_counts = {task: 0 for task in task_names}
    # ä¿å­˜é”™è¯¯åˆ—è¡¨
    misclassified_samples = {task: [] for task in task_names}

    with torch.no_grad():
        for batch in data_loader:
            if batch is None:
                continue
            
            pixel_values, labels_dict, img_paths = batch
            batch_size = pixel_values.size(0)
            pixel_values = pixel_values.to(device)

            predictions_dict = model(pixel_values)
            combined_loss = 0

            for task_name in task_names:
                labels = labels_dict[task_name].to(device)
                predictions = predictions_dict[task_name]
                target = labels.float().view(-1, 1)
                
                # è®¡ç®—æŸå¤±
                task_loss = criterion(predictions, target)
                combined_loss += task_loss
                
                # ç´¯åŠ æŸå¤±å’Œæ ·æœ¬æ•°
                task_counts[task_name] += batch_size
                if num_classes_dict.get(task_name) and num_classes_dict[task_name] > 1:
                    # å¤šåˆ†ç±»ä»»åŠ¡ (å¦‚æœå­˜åœ¨)
                    probabilities = torch.softmax(predictions, dim=1)
                else:
                    probs_pos = torch.sigmoid(predictions).squeeze(1) # å½¢çŠ¶ [N]
                    # æ„é€  N x 2 çš„æ¦‚ç‡ [P(0), P(1)]
                    probabilities = torch.stack([1 - probs_pos, probs_pos], dim=1) # å½¢çŠ¶ [N, 2]
                
                # 2. æ”¶é›†æ¦‚ç‡ (åˆ—è¡¨çš„åˆ—è¡¨: [æ ·æœ¬æ•°, ç±»åˆ«æ•°])
                task_probs[task_name].extend(probabilities.cpu().tolist())
                
                # æ”¶é›†é¢„æµ‹å’Œæ ‡ç­¾
                # å¯¹äº CrossEntropyLossï¼Œé¢„æµ‹æ˜¯ argmax
                preds = (predictions.squeeze(1) > 0).long()
                task_preds[task_name].extend(preds.cpu().tolist())
                task_labels[task_name].extend(labels.cpu().tolist())
                true_labels_cpu = labels.cpu().tolist()
                preds_cpu = preds.cpu().tolist()

                for path, true_label, pred_label in zip(img_paths, true_labels_cpu, preds_cpu):
                    if true_label != pred_label:
                        misclassified_samples[task_name].append({
                            'path': path,
                            'true_label': true_label,
                            'predicted_label': pred_label,
                            'task_name': task_name 
                        })

            total_combined_loss += combined_loss.item()
            
    # è®¡ç®—å¹³å‡æ€»æŸå¤±
    avg_combined_loss = total_combined_loss / len(data_loader)

    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡ (ä¾‹å¦‚ï¼šAccuracy, F1 Score)
    task_metrics = {}
     # å‡è®¾å·²å®‰è£… sklearn
    
    for task_name in task_names:
        true_labels = task_labels[task_name]
        predictions = task_preds[task_name]
        probabilities = task_probs[task_name]
        current_mode = f'{mode}_{task_name}'
        
        if len(true_labels) > 0:
            unique_labels = sorted(list(set(true_labels)))
            pos_label = 1
            metrics = calculate_metrics_binarized(
                all_labels=true_labels,
                all_preds=predictions,
                all_probs=probabilities,
                unique_labels=unique_labels,
                pos_label=pos_label,
                mode=current_mode,
                logger=logger
            )
            task_metrics[task_name] = metrics
        else:
            task_metrics[task_name] = {'accuracy': 0.0, 'f1': 0.0, 'auroc': float('nan'), 'auprc': float('nan')}

    # è¿”å›æ‰€æœ‰ç»“æœ
    return avg_combined_loss, task_metrics, misclassified_samples


# --- è¾…åŠ©å‡½æ•°ï¼šTensorBoard è®°å½• ---
def log_metrics_to_tensorboard(
    writer: SummaryWriter, 
    metrics_dict: Dict[str, Dict[str, float]], 
    total_loss: float,
    step: int, 
    stage: str, 
    logger: logging.Logger,
    ovr_tasks_map: Dict[str, List[str]] 
):
    """
    å°†æ‰€æœ‰æŒ‡æ ‡ï¼ˆaccuracy, precision, recall, f1, auroc, auprcï¼‰æŒ‰ä»»åŠ¡ç±»å‹èšåˆåå†™å…¥ TensorBoardã€‚
    """
    all_task_names = list(metrics_dict.keys())
    ovr_parent_tasks = list(ovr_tasks_map.keys()) 
    ovr_sub_tasks = [sub for subs in ovr_tasks_map.values() for sub in subs] 
    independent_tasks = [
        task for task in all_task_names 
        if task not in ovr_parent_tasks and task not in ovr_sub_tasks
    ]
    
    # æ‰€æœ‰ç‹¬ç«‹å­ä»»åŠ¡ï¼ˆç”¨äºæ€»ä½“å¹³å‡ï¼‰
    all_individual_metrics = {
        'accuracy': [],
        'precision': [],
        'recall': [],
        'f1': [],
        'auroc': [],
        'auprc': []
    }

    logger.info(f"--- {stage} Epoch {step} ä»»åŠ¡æ‘˜è¦æŒ‡æ ‡ ---")

    # 1. å¤„ç† OvR çˆ¶ä»»åŠ¡ï¼šå¯¹å…¶å­ä»»åŠ¡æ±‚å¹³å‡
    for parent_task in ovr_parent_tasks:
        sub_tasks = ovr_tasks_map.get(parent_task, [])
        parent_metrics = {k: [] for k in all_individual_metrics.keys()}

        for sub_task in sub_tasks:
            metrics = metrics_dict.get(sub_task, {})
            if not metrics:
                continue
            for key in all_individual_metrics:
                val = metrics.get(key, float('nan'))
                if not np.isnan(val):
                    parent_metrics[key].append(val)
                    all_individual_metrics[key].append(val)

        # è®¡ç®—çˆ¶ä»»åŠ¡å¹³å‡å¹¶å†™å…¥ TensorBoard
        for key, vals in parent_metrics.items():
            if vals:
                mean_val = np.mean(vals)
                writer.add_scalar(f'{stage}_Summary/{key.upper()}_{parent_task}', mean_val, step)
        
        # æ—¥å¿—æ‰“å°ï¼ˆå¯é€‰ï¼šåªæ‰“å°å…³é”®æŒ‡æ ‡ï¼‰
        mean_auroc = np.mean(parent_metrics['auroc']) if parent_metrics['auroc'] else float('nan')
        mean_f1 = np.mean(parent_metrics['f1']) if parent_metrics['f1'] else float('nan')
        logger.info(f"  OvR Parent '{parent_task}': AUROC={mean_auroc:.4f}, F1={mean_f1:.4f}")

    # 2. å¤„ç†ç‹¬ç«‹ä»»åŠ¡
    for task_name in independent_tasks:
        metrics = metrics_dict.get(task_name, {})
        if not metrics:
            continue
        for key in all_individual_metrics:
            val = metrics.get(key, float('nan'))
            if not np.isnan(val):
                writer.add_scalar(f'{stage}_Summary/{key.upper()}_{task_name}', val, step)
                all_individual_metrics[key].append(val)

    # 3. è®°å½•æ€»ä½“å¹³å‡æŒ‡æ ‡ï¼ˆæ‰€æœ‰å­ä»»åŠ¡ + ç‹¬ç«‹ä»»åŠ¡ï¼‰
    for key, vals in all_individual_metrics.items():
        if vals:
            mean_val = np.mean(vals)
            writer.add_scalar(f'{stage}_Aggregated/Mean_{key.upper()}', mean_val, step)


# --- è®­ç»ƒå‡½æ•° (æ–°å¢æ—¥å¿—å’Œæ—©åœé€»è¾‘) ---
def train_multi_task_classifier(logger: logging.Logger, val_split_ratio: float = 0.2, random_seed: int = 42):
    # 1. åˆå§‹åŒ–é¢„å¤„ç†å™¨
    processor = AutoImageProcessor.from_pretrained(MODEL_NAME)

    # --- TENSORBOARD åˆå§‹åŒ– ---
    # ä½¿ç”¨æ—¥å¿—æ–‡ä»¶åä½œä¸º log_dir çš„ä¸€éƒ¨åˆ†ï¼Œç¡®ä¿æ¯æ¬¡è¿è¡Œçš„æ—¥å¿—ç‹¬ç«‹
    TENSORBOARD_LOG_DIR = os.path.join(f'runs/', FILENAME)
    writer = SummaryWriter(log_dir=TENSORBOARD_LOG_DIR)
    logger.info(f"TensorBoard Writer initialized at: {TENSORBOARD_LOG_DIR}")
    

    # 2. åˆå§‹åŒ–æ•´ä¸ªæ•°æ®é›†å¹¶è¿›è¡Œåˆ†å‰²
    try:
        train_dataset = MultiTaskImageDataset(
            root_dir=DATA_ROOT, csv_path=TRAIN_CSV_PATH, img_col=IMAGE_PATH_COLUMN,
            label_cols=LABEL_COLUMNS, processor=processor, size=TARGET_IMAGE_SIZE,
            logger=logger,is_training=True
        )
    except Exception as e:
        logger.critical(f"è‡´å‘½é”™è¯¯ï¼šè®­ç»ƒæ•°æ®é›†åŠ è½½å¤±è´¥ã€‚è¯·æ£€æŸ¥è·¯å¾„å’Œ CSV æ–‡ä»¶ã€‚")
        logger.critical(e)
        return

    task_names = train_dataset.all_task_names 
    num_classes_dict = {task: 1 for task in task_names} ## å¼ºåˆ¶å°†æ‰€æœ‰ä»»åŠ¡çš„è¾“å‡ºç±»åˆ«æ•°è®¾ç½®ä¸º 1ï¼Œä»¥é€‚åº” nn.BCEWithLogitsLoss
    fitted_encoders = {
        'label_encoders': train_dataset.label_encoders,
        'ovr_tasks_map': train_dataset.ovr_tasks_map,
        'all_task_names': train_dataset.all_task_names # ä¼ é€’æ‰€æœ‰ä»»åŠ¡åä»¥ç¡®ä¿éªŒè¯é›†ç»“æ„ä¸€è‡´
    }

    #  ç±»åˆ«ä¸å¹³è¡¡æƒé‡
    task_weights = {}
    total_samples = len(train_dataset)

    for task_name in task_names:
        # OvR ä»»åŠ¡çš„æ ‡ç­¾åˆ—å·²ç»æ·»åŠ åˆ° train_dataset.df ä¸­ (å€¼ä¸º 0 æˆ– 1)
        pos_count = train_dataset.df[task_name].sum()
        neg_count = total_samples - pos_count
        
        if pos_count > 0 and neg_count > 0:
            # è®¡ç®— pos_weight = è´Ÿæ ·æœ¬ / æ­£æ ·æœ¬
            weight = neg_count / pos_count
            task_weights[task_name] = torch.tensor([weight], dtype=torch.float32).to(DEVICE)
            logger.info(f"ä»»åŠ¡ '{task_name}' (æ­£æ ·æœ¬: {pos_count}, è´Ÿæ ·æœ¬: {neg_count}) -> Pos Weight: {weight:.2f}")
        else:
            # å¦‚æœæŸä¸ªç±»åˆ«çš„æ ·æœ¬æ•°ä¸º0ï¼Œåˆ™ä¸è¿›è¡ŒåŠ æƒ (æƒé‡ä¸º 1.0)
            task_weights[task_name] = torch.tensor([1.0], dtype=torch.float32).to(DEVICE)
            logger.warning(f"ä»»åŠ¡ '{task_name}' æ ·æœ¬æ•°ä¸è¶³ (æ­£: {pos_count})ï¼Œä¸åº”ç”¨åŠ æƒã€‚")


    logger.info(f"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
    logger.info(f"æ‰€æœ‰äºŒåˆ†ç±»ä»»åŠ¡åˆ—è¡¨ (å« OvR): {task_names}")


    # åŠ è½½éªŒè¯æ•°æ®é›† (ä½¿ç”¨è®­ç»ƒé›†ç¼–ç å™¨)
    try:
        val_dataset = MultiTaskImageDataset(
            root_dir=DATA_ROOT, csv_path=VAL_CSV_PATH, img_col=IMAGE_PATH_COLUMN,
            label_cols=LABEL_COLUMNS, processor=processor, size=TARGET_IMAGE_SIZE,
            logger=logger, 
            fitted_encoders=fitted_encoders,is_training=False
        )
    except Exception as e:
        logger.critical(f"è‡´å‘½é”™è¯¯ï¼šéªŒè¯é›†åŠ è½½å¤±è´¥ã€‚è¯·æ£€æŸ¥è·¯å¾„å’Œ CSV æ–‡ä»¶ ({VAL_CSV_PATH})ã€‚")
        logger.critical(e)
        return
    
    logger.info(f"éªŒè¯é›†å¤§å°: {len(val_dataset)}")
    train_ovr_tasks_map = train_dataset.ovr_tasks_map 
    val_ovr_tasks_map = val_dataset.ovr_tasks_map

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, 
                              num_workers=8, collate_fn=custom_collate_fn, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, 
                            num_workers=8, collate_fn=custom_collate_fn, pin_memory=True)

    # åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    model = DinoV3MultiTaskClassifier(MODEL_NAME, num_classes_dict).to(DEVICE)
    # åˆ›å»ºä»»åŠ¡ç‰¹å®šçš„åŠ æƒæŸå¤±å‡½æ•°å­—å…¸
    criterion_dict = {}
    for task_name, weight in task_weights.items():
        criterion_dict[task_name] = nn.BCEWithLogitsLoss(pos_weight=weight, reduction='mean')
    
    # ç”¨äºè¯„ä¼°çš„æŸå¤±å‡½æ•°é€šå¸¸ä¸åŠ æƒï¼Œä»¥åæ˜ çœŸå®æŸå¤±
    unweighted_criterion = nn.BCEWithLogitsLoss(reduction='mean')
    # ä»…ä¼˜åŒ–åˆ†ç±»å¤´å‚æ•° (å‡è®¾ä¸»å¹²ç½‘ç»œå†»ç»“)
    optimizer = torch.optim.AdamW(model.classifiers.parameters(), lr=LEARNING_RATE,weight_decay=WEIGHT_DECAY)

    # åˆå§‹åŒ– GradScaler
    scaler = torch.amp.GradScaler('cuda')

    logger.info(f"æ¨¡å‹å·²åŠ è½½ï¼Œåœ¨è®¾å¤‡ {DEVICE} ä¸Šè®­ç»ƒ...")

    best_val_score = -1.0
    patience_counter = 0

    best_epoch_val_misclassified_samples: Dict[str, List[Dict[str, Any]]] = {}
    best_epoch_train_misclassified_samples: Dict[str, List[Dict[str, Any]]] = {}
    best_epoch = -1

    # 4. è®­ç»ƒå¾ªç¯
    for epoch in range(NUM_EPOCHS):
        total_combined_loss = 0
        train_labels_all = {task: [] for task in task_names}
        train_preds_all = {task: [] for task in task_names}
        train_probs_all = {task: [] for task in task_names}
        train_paths_all = []
        model.train()

        # è®­ç»ƒæ­¥éª¤
        for step, batch in enumerate(train_loader):
            if batch is None:
                logger.warning("Received an empty batch after filtering corrupt files. Skipping step.")
                continue
            pixel_values, labels_dict, img_paths = batch
            batch_size = pixel_values.size(0)
            pixel_values = pixel_values.to(DEVICE)
            for task in labels_dict:
                labels_dict[task] = labels_dict[task].to(DEVICE)

            optimizer.zero_grad()
            combined_loss = 0.0
            train_paths_all.extend(img_paths)

            with torch.amp.autocast(device_type=DEVICE):
                predictions_dict = model(pixel_values)
                for task_name in model.task_names:
                    predictions = predictions_dict[task_name]  # shape: (batch_size, 1)
                    labels = labels_dict[task_name]            # shape: (batch_size)
                    target = labels.float().view(-1, 1)

                    # 1. æŸå¤±è®¡ç®—
                    task_criterion = criterion_dict[task_name]
                    task_loss = task_criterion(predictions, target)
                    combined_loss += task_loss # ç´¯åŠ æ€»æŸå¤±

                    # 2. è®­ç»ƒé›†æŒ‡æ ‡ç§¯ç´¯ (æ‰€æœ‰ä»»åŠ¡)
                    predictions_logits = predictions.squeeze(1) # shape: (batch_size)
                    probs = torch.sigmoid(predictions_logits) 
                    
                    train_probs_all[task_name].extend(probs.cpu().tolist())
                    preds = (probs > 0.5).long()
                    train_preds_all[task_name].extend(preds.cpu().tolist())
                    safe_labels_list = labels.cpu().reshape(-1).tolist() 
                    train_labels_all[task_name].extend(safe_labels_list)

            scaler.scale(combined_loss).backward()
            scaler.step(optimizer)
            scaler.update()
            total_combined_loss += combined_loss.item()
            
            # è®°å½•è¿­ä»£è®­ç»ƒæŸå¤±
            if step % 50 == 0 and step > 0:
                print(f"Epoch {epoch + 1}/{NUM_EPOCHS}, Step {step}/{len(train_loader)}, "
                        f"Total Train Loss: {combined_loss.item():.4f}")

        avg_train_loss = total_combined_loss / len(train_loader)

        # --- è®­ç»ƒè¯„ä¼°
        logger.info(f"--------- Epoch {epoch + 1} è®­ç»ƒè¯„ä¼°æ€»ç»“ --------")
        train_metrics = {}
        misclassified_train_samples = {task: [] for task in task_names}
        for task_name in task_names:
            # è¿™é‡Œçš„ lists ç°åœ¨åŒ…å«äº†æ‰€æœ‰ä»»åŠ¡çš„æ•°æ®
            true_labels = train_labels_all[task_name]
            predictions = train_preds_all[task_name]
            probabilities = [[1-p, p] for p in train_probs_all[task_name]]
            metrics = calculate_metrics_binarized(
                all_labels=train_labels_all[task_name],
                all_preds=train_preds_all[task_name],
                all_probs=[[1-p, p] for p in train_probs_all[task_name]], 
                unique_labels=[0, 1],
                pos_label=1,
                mode=f'train_{task_name}',
                logger=logger
            )
            train_metrics[task_name] = metrics
            for path, true_label, pred_label in zip(train_paths_all, true_labels, predictions):
                    if true_label != pred_label:
                        misclassified_train_samples[task_name].append({
                            'path': path,
                            'true_label': true_label,
                            'predicted_label': pred_label,
                            'task_name': task_name 
                        })

        log_metrics_to_tensorboard(
            writer, 
            train_metrics, 
            avg_train_loss, # ä¼ é€’æ€»æŸå¤±
            epoch + 1, 
            'Train', 
            logger,
            ovr_tasks_map=train_ovr_tasks_map
        )

        # --- Epoch ç»“æŸåçš„è¯„ä¼° ---
        logger.info(f"--------- Epoch {epoch + 1} éªŒè¯è¯„ä¼°æ€»ç»“ --------")
        val_loss, val_metrics, misclassified_val_samples = evaluate(
            model, val_loader, unweighted_criterion, model.task_names, num_classes_dict, DEVICE, mode='val', logger=logger
        )
        log_metrics_to_tensorboard(
            writer, 
            val_metrics, 
            val_loss, # ä¼ é€’æ€»æŸå¤±
            epoch + 1, 
            'Val', 
            logger,
            ovr_tasks_map=val_ovr_tasks_map
        )
        
        # --- æ—©åœå’Œæ¨¡å‹ä¿å­˜é€»è¾‘æ›´æ–° ---
        key_task = task_names[0]
        val_score = val_metrics[key_task].get('accuracy', val_metrics[key_task].get('f1', 0.0))
        if val_score > best_val_score:
            best_val_score = val_score
            patience_counter = 0
            best_epoch = epoch + 1
            best_epoch_train_misclassified_samples = misclassified_train_samples 
            best_epoch_val_misclassified_samples = misclassified_val_samples
            logger.info(f"æœ€ä½³æ¨¡å‹aucåˆ†æ•°: {best_val_score:.4f}")
        else:
            patience_counter += 1
            logger.info(f"ğŸ–¤éªŒè¯æœªæ”¹å–„ã€‚å½“å‰è€å¿ƒå€¼: {patience_counter}/{PATIENCE}")
            if patience_counter >= PATIENCE:
                logger.info(f"ğŸ›‘ æ—©åœè§¦å‘ï¼åœ¨ Epoch {epoch + 1} åœæ­¢è®­ç»ƒã€‚")
                break

    logger.info("\nå¤šä»»åŠ¡è®­ç»ƒå®Œæˆï¼")
    if best_epoch > 0:
        MISCLASSIFIED_OUTPUT_DIR = os.path.join(TENSORBOARD_LOG_DIR, 'misclassified')
        os.makedirs(MISCLASSIFIED_OUTPUT_DIR , exist_ok=True)
        
        all_errors = []
        
        # --- æ”¶é›†è®­ç»ƒé›†é”™è¯¯ ---
        for task_name, errors in best_epoch_train_misclassified_samples.items():
            for error in errors:
                error['epoch'] = best_epoch 
                error['subset'] = 'train' # æ ‡è®°ä¸ºè®­ç»ƒé›†
                all_errors.append(error)

        # --- æ”¶é›†éªŒè¯é›†é”™è¯¯ ---
        for task_name, errors in best_epoch_val_misclassified_samples.items():
            for error in errors:
                error['epoch'] = best_epoch 
                error['subset'] = 'val' # æ ‡è®°ä¸ºéªŒè¯é›†
                all_errors.append(error)

        if all_errors:
            error_df = pd.DataFrame(all_errors)
            
            # âš ï¸ ä½¿ç”¨å›ºå®šåç§°ï¼Œå®ç°è¦†ç›– (å¦‚æœè·¯å¾„å­˜åœ¨)
            output_path = os.path.join(MISCLASSIFIED_OUTPUT_DIR, f'{best_epoch}_misclassified.csv')
            
            # åªä¿ç•™å…³é”®åˆ—ï¼Œå¹¶ä¿å­˜
            error_df[['subset', 'epoch', 'task_name', 'path', 'true_label', 'predicted_label']].to_csv(output_path, index=False)
            logger.info(f"ğŸ‰ æœ€ç»ˆä¿å­˜ï¼šå·²å°†æœ€ä½³ Epoch ({best_epoch}) çš„ {len(all_errors)} ä¸ª (Train+Val) é”™è¯¯æ ·æœ¬è®°å½•åˆ° {output_path}")
        else:
             logger.info(f"æœ€ä½³ Epoch ({best_epoch}) æ²¡æœ‰è®°å½•åˆ°ä»»ä½•é”™è¯¯æ ·æœ¬ã€‚")
    writer.close() # ç¡®ä¿æ‰€æœ‰æ•°æ®å†™å…¥æ—¥å¿—æ–‡ä»¶
    return None


if __name__ == "__main__":
    # åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨
    main_logger = setup_logging()
    main_logger.info(f"æ—¥å¿—æ–‡ä»¶å·²åˆ›å»ºï¼š{LOG_FILENAME}")
    main_logger.info(f"è¿è¡Œè®¾å¤‡: {DEVICE}")
    main_logger.info(f"å›¾åƒå°ºå¯¸: {TARGET_IMAGE_SIZE}")
    main_logger.info(f"BATCH_SIZE: {BATCH_SIZE}")
    main_logger.info(f"LEARNING_RATE: {LEARNING_RATE}")

    trained_model = train_multi_task_classifier(main_logger)

    if trained_model:
        main_logger.info("\næœ€ç»ˆæ¨¡å‹å·²è®­ç»ƒå¹¶åŠ è½½ã€‚")
